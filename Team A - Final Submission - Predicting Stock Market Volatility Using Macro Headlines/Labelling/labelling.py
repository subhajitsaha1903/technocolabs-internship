# -*- coding: utf-8 -*-
"""labelling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oi1eWkD1gJMvQ9tPAcRkV1kIyvzmQmWJ
"""

# Importing Libraries 
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import warnings 
warnings.filterwarnings("ignore", category=DeprecationWarning)
# Loading Data
stock_data_amazon= pd.read_csv('amazon_hist_6months.csv') 
stock_data_amazon['Symbol']='Amazon'
stock_data_apple= pd.read_csv('apple_hist_6months.csv')
stock_data_apple['Symbol']='Apple'
stock_data_msft= pd.read_csv('msft_hist_6months.csv')
stock_data_msft['Symbol']='Microsoft'
stock_data_tesla= pd.read_csv('tesla_hist_6months.csv')
stock_data_tesla['Symbol']='Tesla'
stock_data_ibm= pd.read_csv('ibm_hist_6months.csv')
stock_data_ibm['Symbol']='IBM'

company_list=[stock_data_apple,stock_data_amazon,stock_data_ibm,stock_data_msft,stock_data_tesla]
for company in company_list:
 #removing the dollar sign and "volume column" from the stock_data
 company['Close']=company['Close/Last'].str.replace('$','')
 company.drop('Close/Last',inplace=True, axis=1)
#stock_data['Avg_Annual'] = stock_data['Avg_Annual'].astype(int)
 company ['Open'] = company ['Open'].str.replace('$', '')
 company ['High'] = company ['High'].str.replace('$', '')
 company ['Low'] = company ['Low'].str.replace('$', '')
 #setting type of fiels to float
 company['Open'] = company['Open'].astype(float)
 company ['High'] = company ['High'].astype(float)
 company ['Low'] = company ['Low'].astype(float)
 company ['Close'] = company ['Close'].astype(float)
 company['Date'] = pd.to_datetime(company['Date'])
 #print (stock_data.shape)
stock_data_tesla

#Filling missing Dates and values using the mean of previous and next day available.
company_list=[stock_data_apple,stock_data_amazon,stock_data_ibm,stock_data_msft,stock_data_tesla]
stock_list=[]
for company in company_list:
 dates = pd.date_range(start=company.Date.min(), end=company.Date.max())
 company=company.set_index('Date').reindex(dates).rename_axis('Date').reset_index()
 company['Volume']=pd.concat([company['Volume'].ffill(), company['Volume'].bfill()]).groupby(level=0).mean()
 company['Close']=pd.concat([company['Close'].ffill(), company['Close'].bfill()]).groupby(level=0).mean()
 company['Open']=pd.concat([company['Open'].ffill(), company['Open'].bfill()]).groupby(level=0).mean()
 company['High']=pd.concat([company['High'].ffill(), company['High'].bfill()]).groupby(level=0).mean()
 company['Low']=pd.concat([company['Low'].ffill(), company['Low'].bfill()]).groupby(level=0).mean()
 company['Symbol']=company['Symbol'].ffill()
 stock_list.append(company)
company

#combining stock data along Axis 0
stock_data_combined = pd.concat(stock_list, axis=0)
stock_data_combined.reset_index()
stock_data_combined.set_index('Date')
stock_data_combined=stock_data_combined.reset_index(drop=True)
stock_data_combined

"""Labelling of stock data"""

#labelling of the stock data using same day approach
stock_data=stock_data_combined
list_label=[]
for i in range(len(stock_data)):
    open_price = stock_data.iloc[i]["Open"]
    close_price = stock_data.iloc[i]["Close"]
    change=round(round(close_price,4)-round(open_price,4),4)
    if int(round(np.sign(change)))==1:
     list_label.append(1)
    else:
     list_label.append(0)
stock_data['lab_sameday']=list_label
stock_data

#labelling of the stock data using previous day approach
list_label_1=[1]
for i in range(1,len(stock_data)):
    close_price_prev_day = stock_data.iloc[i-1]["Close"]
    close_price_curr_day = stock_data.iloc[i]["Close"]
    change=round(round(close_price_curr_day,4)-round(close_price_prev_day,4),4)
    if int(round(np.sign(change)))==1:
     list_label_1.append(1)
    else:
     list_label_1.append(0)
stock_data['lab_prevday']=list_label_1
stock_data

#Merging twitter data with stock data by company name.
#read grouped csv files
twitter_NLP_amazon= pd.read_csv('AMZN_grouped_sentiment_double_singleday.csv') 
twitter_NLP_apple= pd.read_csv('AAPL_grouped_sentiment_double_singleday.csv') 
twitter_NLP_ibm= pd.read_csv('IBM_grouped_sentiment_double_singleday.csv') 
twitter_NLP_microsoft= pd.read_csv('MSFT_grouped_sentiment_double_singleday.csv') 
twitter_NLP_tesla= pd.read_csv('TSLA_grouped_sentiment_double_singleday.csv') 
#combining NLP files
twitter_NLP_list=[twitter_NLP_apple,twitter_NLP_amazon,twitter_NLP_ibm,twitter_NLP_microsoft,twitter_NLP_tesla]
twitter_NLP_combined = pd.concat(twitter_NLP_list, axis=0)
twitter_NLP_combined['Date'] = pd.to_datetime(twitter_NLP_combined['Date'])
twitter_NLP_combined=twitter_NLP_combined.reset_index(drop=True)
twitter_NLP_combined

#merging twitter NLP data and stock data on columns Date and Symbol
df_merged = pd.merge(twitter_NLP_combined, stock_data, on=['Date','Symbol'], how='inner')
df_merged.rename(columns = {'polarity':'Polarity'}, inplace = True)

#selecting only the wanted columns
df_merged_final=df_merged[['Date','lab_sameday','Polarity']]
df_merged_final

#selecting only the wanted columns
df_merged_final1=df_merged[['Date','lab_sameday','Polarity','Open','Close','Volume','Low','High']]
df_merged_final1

#df_merged_final.to_csv('/content/drive/MyDrive/stock_data_mine/labelled_dataset_sentiment_sameday_deployment_singleday.csv', index=False)

#df_merged_final1.to_csv('/content/drive/MyDrive/stock_data_mine/labelled_dataset_sentiment_sameday_deployment_singleday_full.csv', index=False)

df_merged_final1.to_csv('labelled_dataset_full.csv', index=False)